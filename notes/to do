## Horn clauses

* See if we can erase more variables in asymmetric2.
* Try encoding a=b&c=d=>e=f in one go rather than several.
    - Problem: may create more critical pairs.
* Try introducing extra function symbols to reduce number of critical pairs.
    - Possible approach: a=b=>c=d becomes something like a=b=>equals_a_b; equals_a_b=>c=d. So each rule only contains one original equation.
* Encode predicates less wastefully.
* Work out how to print conditional proofs nicely. Possibly transform proofs into form:

    Lemma: p => q

    Proof: p => ... = ... => q

* Work out how to print conditional proofs _at all_. Possible idea: transform axioms into proofs, e.g. $ifeq(x,x,y,z) might become (x=x=>y=z)<=>(y=z), then somehow lift transitivity to this setting. Alternatively interpret $ifeq as if-then-else and then simplify the proof.

## More extensions

* One-sided choice functions for classical reasoning.
* Theory reasoning.
* SAT-driven loop.
* Goal direction from paper. Look for redundancy criterion for when forward chaining is unnecessary.
* Restarts/dynamic ordering.
    - When we discover the crucial lemma, it causes bajillions of existing
      rules to be discarded. Can we somehow use this as a similar/boringness
      metric on these existing rules? (The fact that there is a single rule
      which will generalise them all.)

## Smaller improvements

* When evaluating CPs, try Skolemising first + apply unorientable rules.
* Keep non-unit goals (have Twee handle them in main loop).
* Proof simplification: if we have a chain of axioms/lemmas t = u = ... = v,
  check to see if the lemma used to prove t = u also works for t = v.
  (This helps with repeated terms in laws, as well as weak laws.)
  Inline weak laws to help with this? Or maybe take the lemma
    t -> t'
  and turn it into
    t -> t' -> rename(t)
  and then fix up all uses of the lemma - the transformation above
  should then clean up everything.
* Use extra rules again [should be OK to rewrite one ground joinable
  term to a smaller one: instance of subconnectedness, or
  alternatively, if we have t -> v <- u and replace t with u then we
  could rewrite t to v before, and now we can rewrite t to u to v].
  Add extra rule when a rule is simplified by ground joining.
* Finish off simplerThan stuff. Make sure it is always use, incl. during connectedness, and define in a more principled way.
* Cancellative laws instead of ifeq hack.
* Case split: try abstracting bigger terms to variables so that we can case split on compound terms.

## Miscellaneous

* Twee assumes that variable numbers are non-negative but the term constructors don't check this. See if we can without hurting performance (possibly: export only a smart constructor for Var, possibly as a pattern synonym).

* Proof of grp196-1 has duplicate lemma numbers

* Look at gt6 - ground joinability testing goes really slow (ROB006-1 too).
  Also, after a while "a" becomes redundant - but we still keep deriving
  stuff from it.

* N.B. if we introduce goal-directness, we must NOT rewrite
  terms t(..., X, ...) backwards with e.g. $equals(t,t)->$true,
  letting X=$true. This is a type error really. Maybe add narrowing before encoding types?

* Do we really need to eagerly generate critical pairs from recently
  generated laws? Maybe gradually notch up maximum age of considered
  critical pairs. E.g.: only consider CPs from rules up to label l/2,
  where l is the current label. Perhaps print out the maximum CP age
  actually used in a proof.

* Suppose we have the rule
    x*x*x*x*x*x -> x
  Then we should give the term
    x*x*x*x*y
  a relatively small weight, because the instance [y->x*x] rewrites to x.
  Somehow, terms that are "close to" being reduced to small terms should
  get a smaller weight.

* For QuickSpec-style "only generate laws up to this size": when a
  critical pair is this size, join it under the constraint X <= c for
  all variables X where c is a maximal constant of size 1. This effectively
  forces all variables to have size one.